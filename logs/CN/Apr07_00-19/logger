2024-04-07 00:19:06,366 : lr: 0.001
2024-04-07 00:19:06,367 : gamma: 0.1
2024-04-07 00:19:06,367 : gamma_rate: 0.002
2024-04-07 00:19:06,367 : gamma_final: 0.9
2024-04-07 00:19:06,367 : tau: 1.0
2024-04-07 00:19:06,368 : entropy: 0.005
2024-04-07 00:19:06,368 : grad_entropy: 1.0
2024-04-07 00:19:06,368 : seed: 1
2024-04-07 00:19:06,368 : workers: 6
2024-04-07 00:19:06,368 : A2C_steps: 10
2024-04-07 00:19:06,368 : env_steps: 10
2024-04-07 00:19:06,368 : start_eps: 2000
2024-04-07 00:19:06,368 : ToM_train_loops: 1
2024-04-07 00:19:06,368 : policy_train_loops: 1
2024-04-07 00:19:06,368 : test_eps: 20
2024-04-07 00:19:06,368 : ToM_frozen: 5
2024-04-07 00:19:06,369 : env: CN
2024-04-07 00:19:06,369 : optimizer: Adam
2024-04-07 00:19:06,369 : amsgrad: True
2024-04-07 00:19:06,369 : load_model_dir: None
2024-04-07 00:19:06,369 : load_executor_dir: None
2024-04-07 00:19:06,369 : log_dir: logs/CN/Apr07_00-19
2024-04-07 00:19:06,369 : model: ToM2C
2024-04-07 00:19:06,369 : gpu_id: [-1]
2024-04-07 00:19:06,369 : norm_reward: True
2024-04-07 00:19:06,369 : train_comm: False
2024-04-07 00:19:06,369 : random_target: True
2024-04-07 00:19:06,370 : mask_actions: False
2024-04-07 00:19:06,370 : mask: False
2024-04-07 00:19:06,370 : render: False
2024-04-07 00:19:06,370 : fix: False
2024-04-07 00:19:06,370 : shared_optimizer: True
2024-04-07 00:19:06,370 : train_mode: -1
2024-04-07 00:19:06,370 : lstm_out: 32
2024-04-07 00:19:06,370 : sleep_time: 0
2024-04-07 00:19:06,370 : max_step: 3000000
2024-04-07 00:19:06,370 : render_save: False
2024-04-07 00:19:06,370 : num_agents: -1
2024-04-07 00:19:06,371 : num_targets: -1
2024-04-07 00:19:11,438 : Time 00h 00m 05s, ave eps reward [-26.46 -26.46 -26.46], ave eps length 10.0, reward step [-2.65 -2.65 -2.65], FPS 39.19, mean reward -26.46281878888804, std reward 8.50625071252438, AG 0.0
